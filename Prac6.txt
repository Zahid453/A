from keras.datasets import imdb
from tensorflow.keras.preprocessing.text import Tokenizer  # Capital "T"
from keras.preprocessing.sequence import pad_sequences
from keras.models import Sequential
from keras.layers import Dense, Embedding, Flatten, SimpleRNN


(x_train, y_train), (x_test, y_test) = imdb.load_data()

print(x_train.shape)
print(len(x_train))
print(x_train[0])


x_train =pad_sequences(x_train, padding="post", maxlen = 50)
x_test = pad_sequences(x_test, padding="post", maxlen = 50)


Model = Sequential()
Model.add(SimpleRNN(32, input_shape=(50,1), return_sequences=False))
Model.add(Dense(1, activation='sigmoid'))
Model.summary()


Model.compile(optimizer="adam", loss = 'binary_crossentropy', metrics=['accuracy'])
Model.fit(x_train,y_test, epochs =50, validation_data = [x_test, y_test])