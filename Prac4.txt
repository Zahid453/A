import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
import warnings

from sklearn.datasets import make_circles
from sklearn.model_selection import train_test_split
from tensorflow import keras
from tensorflow.keras import layers, Sequential
from tensorflow.keras.layers import Dense
from mlxtend.plotting import plot_decision_regions


x,y = make_circles(n_samples = 100, noise = 0.1, random_state =1)
sns.scatterplot(x=x[:, 0], y=x[:, 1], hue=y)


xtrain, xtest, ytrain, ytest = train_test_split(x,y, test_size=0.2, random_state = 2)


Model = Sequential()
Model.add(Dense(256, activation='relu', input_dim = 2))
Model.add(Dense(1, activation='sigmoid'))
Model.summary()


Model.compile(loss='binary_crossentropy', optimizer='Adam', metrics=['accuracy'])


History = Model.fit(xtrain,ytrain,validation_data=(xtest,ytest), epochs=35,verbose = 0)



plt.plot(History.history['loss'], label='train')
plt.plot(History.history['val_loss'], label='test')
plt.legend()
plt.show()


plot_decision_regions(xtest, ytest.ravel(), clf =Model, legend=2)
plt.show()



Implementation of Early Stopping

from tensorflow.keras import callbacks
from tensorflow.keras.callbacks import EarlyStopping

Model = Sequential()
Model.add(Dense(256, input_dim = 2, activation = 'relu'))
Model.add(Dense(1, activation='sigmoid'))
Model.compile(loss='binary_crossentropy', optimizer = 'adam', metrics=['accuracy'])

callbacks = EarlyStopping(
    monitor = "val_loss",
    min_delta = 0.00001,
    patience = 20,
    verbose = 1,
    mode = 'auto',
    baseline = None,
    restore_best_weights = False
)
History = Model.fit(xtrain,ytrain,validation_data=(xtest,ytest), epochs=3500,callbacks=callbacks)



plt.plot(History.history['loss'], label='train')
plt.plot(History.history['val_loss'], label='test')
plt.legend()
plt.show()


splot_decision_regions(xtest, ytest.ravel(), clf = Model, legend=2)
plt.show()

