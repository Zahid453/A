import numpy as np
import matplotlib.pyplot as plt

from tensorflow import keras
from tensorflow.keras import layers, Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.layers import Dense, Dropout



x_train = np.linspace(-1, 1, 20)
y_train = np.array([-0.6561, -0.3099, -0.59035, -0.50855, -0.285,
                    -0.2443, -0.02445, 0.00135, -0.2006, 0.07475,
                    -0.1422, 0.06515, 0.15265, 0.3521, 0.28415,
                    0.5524, 0.23115, 0.20835, 0.4211, 0.60485])

x_test = np.linspace(-1, 1, 20)
y_test = np.array([-0.69415, -0.451, -0.43005, -0.4484, -0.1475,
                   -0.5019, -0.28055, 0.24595, -0.21425, -0.0286,
                   0.23415, 0.46575, 0.07955, 0.1973, 0.0719,
                   0.3639, 0.5536, 0.3365, 0.50705, 0.33435])

plt.scatter(x_train, y_train, c='red', label='Train')
plt.scatter(x_test, y_test, c='blue', label='Test')
plt.legend()
plt.show()



Model = Sequential()
Model.add(Dense(128, input_dim = 1, activation='relu'))
Model.add(Dense(128, activation='relu'))
Model.add(Dense(1, activation='linear'))



adam = Adam(learning_rate = 0.01)
Model.compile(loss = 'mse', optimizer = adam, metrics = ['mse'])
History = Model.fit(x_train, y_train, epochs=500, validation_data = (x_test, y_test), verbose = False)


_, train_mse = Model.evaluate(x_train, y_train, verbose=0)
_, test_mse = Model.evaluate(x_test, y_test, verbose=0)
print('Train : {}, Test: {}'.format(train_mse, test_mse))



y_pred_1 = Model.predict(x_test)

plt.figure()
plt.scatter(x_train, y_train, c='red', label='Train')
plt.scatter(x_test, y_test, c='blue', label='Test')
plt.plot(x_test, y_pred_1, label='Prediction')
plt.legend()
plt.ylim((-1.5, 1.5))
plt.show()



Dropout Model

model_2 = Sequential()
model_2.add(Dense(128, input_dim=1, activation="relu"))
model_2.add(Dropout(0.2))
model_2.add(Dense(128, activation="relu"))
model_2.add(Dropout(0.5)) # 50% # Also check for 20
model_2.add(Dense(1, activation="linear"))

adam = Adam(learning_rate=0.01)
model_2.compile(loss='mse', optimizer=adam, metrics=['mse'])

drop_out_history = model_2.fit(
    x_train, y_train,
    epochs=500,
    validation_data=(x_test, y_test),
    verbose=False
)

_, train_mse = model_2.evaluate(x_train, y_train, verbose=0)
_, test_mse = model_2.evaluate(x_test, y_test, verbose=0)
print('Train : {}, Test: {}'.format(train_mse, test_mse))


y_pred_2 = model_2.predict(x_test)

plt.figure()
plt.scatter(x_train, y_train, c='red', label='Train')
plt.scatter(x_test, y_test, c='blue', label='Test')
plt.plot(x_test, y_pred_2, label='Prediction')
plt.legend()
plt.ylim((-1.5, 1.5))
plt.show()